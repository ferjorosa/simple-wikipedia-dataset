{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Objective\n",
    "\n",
    "The goal of this notebook is to explore and analyze processed Wikipedia texts with the help of the **DeepSeek V3 model**, focusing on the following:\n",
    "\n",
    "- Counting the number of tokens in the articles.\n",
    "- Identifying patterns that can help in filtering or further processing the data.\n",
    "\n",
    "We will begin by loading the processed Parquet file, which contains the titles and contents of Simple English Wikipedia articles, and use the DeepSeek V3 model for deeper analysis.\n",
    "\n",
    "The conclusions taken here will be later applied in the pipeline for the dataset generation.\n"
   ],
   "id": "9e9f75631da9263c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-31T17:43:12.207294Z",
     "start_time": "2024-12-31T17:43:06.666004Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from os import getenv\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from transformers import AutoTokenizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "load_dotenv()\n",
    "tqdm.pandas()"
   ],
   "id": "ef332b40459c1a1f",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load data",
   "id": "ddaee845e3f4f176"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-31T17:30:54.045476Z",
     "start_time": "2024-12-31T17:30:53.424750Z"
    }
   },
   "source": "data = pd.read_parquet(\"../dump/processed/data.parquet\")",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load tokenizer",
   "id": "49789fde7a8d96e0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-31T17:30:54.578216Z",
     "start_time": "2024-12-31T17:30:54.139866Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_hf = \"deepseek-ai/DeepSeek-V3\"\n",
    "\n",
    "# Retrieve the Hugging Face token from the environment variables\n",
    "huggingface_token = getenv(\"HUGGINGFACE_TOKEN\")\n",
    "\n",
    "# Load the tokenizer using the Hugging Face token for authentication\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_hf, token=huggingface_token)"
   ],
   "id": "7baaaad79d98f855",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Count tokens",
   "id": "1cb9ee0b5e3a5eda"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-31T17:32:45.429863Z",
     "start_time": "2024-12-31T17:30:54.589035Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function to count tokens\n",
    "def count_tokens(text):\n",
    "    return len(tokenizer.encode(text))\n",
    "\n",
    "# Apply the function to each row in the 'text' column with a progress bar\n",
    "data['token_count'] = data['text'].progress_apply(count_tokens)\n",
    "\n",
    "# Print the first row to verify\n",
    "print(f\"Token count: {data['token_count'].sum()}\")"
   ],
   "id": "fa59e61377129e8a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 258559/258559 [01:50<00:00, 2334.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token count: 86522240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Explore low-count articles\n",
    "\n",
    "We observe there are 80K low-count articles with 20 - 100 tokens and only a few \"empty\" articles (<10 tokens)"
   ],
   "id": "adf496340990f0f3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-31T18:04:26.486918Z",
     "start_time": "2024-12-31T18:04:26.468575Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(data[(data[\"token_count\"] < 15)].shape)\n",
    "print(data[(data[\"token_count\"] < 30) & (data[\"token_count\"] >= 20)].shape)\n",
    "\n",
    "data[(data[\"token_count\"] < 15)]"
   ],
   "id": "eb6f889580f0ddcc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22, 5)\n",
      "(5990, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                      title  \\\n",
       "1184                                 Global   \n",
       "2852                                    587   \n",
       "20373        List of professional wrestlers   \n",
       "28294                                    UA   \n",
       "70479                                    62   \n",
       "85449                                Across   \n",
       "220790                                  Den   \n",
       "220927                             Bludgeon   \n",
       "244390                               Cringe   \n",
       "250774                            Vindicate   \n",
       "251334                             Loophole   \n",
       "252376                               Format   \n",
       "252377                               Layout   \n",
       "252378                            Discharge   \n",
       "252379                             Footnote   \n",
       "252380                              Absence   \n",
       "252381                            Accessory   \n",
       "252382                            Arbitrary   \n",
       "258230  The True Story of the 3 Little Pigs   \n",
       "258516     The Grand Old Duke of Noble York   \n",
       "258517                  Naughty Sock (1997)   \n",
       "258519                  Playing in the Rain   \n",
       "\n",
       "                                                     text       id  \\\n",
       "1184                                       = Global =\\n\\n     4550   \n",
       "2852            = 587 =\\n\\n== Deaths ==\\n\\n * Saint David     9257   \n",
       "20373              = List of professional wrestlers =\\n\\n    79924   \n",
       "28294   = UA =\\n\\nUA may mean: * Ukraine * University ...   117032   \n",
       "70479                               = 62 =\\n\\nCategory:62   303542   \n",
       "85449                                      = Across =\\n\\n   378807   \n",
       "220790                                        = Den =\\n\\n   983477   \n",
       "220927                                   = Bludgeon =\\n\\n   983922   \n",
       "244390                                     = Cringe =\\n\\n  1085406   \n",
       "250774                                  = Vindicate =\\n\\n  1120393   \n",
       "251334                                   = Loophole =\\n\\n  1124072   \n",
       "252376                                     = Format =\\n\\n  1130641   \n",
       "252377                                     = Layout =\\n\\n  1130642   \n",
       "252378                                  = Discharge =\\n\\n  1130643   \n",
       "252379                                   = Footnote =\\n\\n  1130644   \n",
       "252380                                    = Absence =\\n\\n  1130645   \n",
       "252381                                  = Accessory =\\n\\n  1130647   \n",
       "252382                                  = Arbitrary =\\n\\n  1130648   \n",
       "258230        = The True Story of the 3 Little Pigs =\\n\\n  1155422   \n",
       "258516           = The Grand Old Duke of Noble York =\\n\\n  1156573   \n",
       "258517                        = Naughty Sock (1997) =\\n\\n  1156574   \n",
       "258519                        = Playing in the Rain =\\n\\n  1156577   \n",
       "\n",
       "        token_count token_bin  \n",
       "1184              4  (0, 100]  \n",
       "2852             13  (0, 100]  \n",
       "20373             8  (0, 100]  \n",
       "28294            14  (0, 100]  \n",
       "70479             8  (0, 100]  \n",
       "85449             4  (0, 100]  \n",
       "220790            4  (0, 100]  \n",
       "220927            6  (0, 100]  \n",
       "244390            5  (0, 100]  \n",
       "250774            6  (0, 100]  \n",
       "251334            6  (0, 100]  \n",
       "252376            4  (0, 100]  \n",
       "252377            4  (0, 100]  \n",
       "252378            5  (0, 100]  \n",
       "252379            4  (0, 100]  \n",
       "252380            5  (0, 100]  \n",
       "252381            5  (0, 100]  \n",
       "252382            5  (0, 100]  \n",
       "258230           13  (0, 100]  \n",
       "258516           10  (0, 100]  \n",
       "258517           11  (0, 100]  \n",
       "258519            7  (0, 100]  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "      <th>token_count</th>\n",
       "      <th>token_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1184</th>\n",
       "      <td>Global</td>\n",
       "      <td>= Global =\\n\\n</td>\n",
       "      <td>4550</td>\n",
       "      <td>4</td>\n",
       "      <td>(0, 100]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2852</th>\n",
       "      <td>587</td>\n",
       "      <td>= 587 =\\n\\n== Deaths ==\\n\\n * Saint David</td>\n",
       "      <td>9257</td>\n",
       "      <td>13</td>\n",
       "      <td>(0, 100]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20373</th>\n",
       "      <td>List of professional wrestlers</td>\n",
       "      <td>= List of professional wrestlers =\\n\\n</td>\n",
       "      <td>79924</td>\n",
       "      <td>8</td>\n",
       "      <td>(0, 100]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28294</th>\n",
       "      <td>UA</td>\n",
       "      <td>= UA =\\n\\nUA may mean: * Ukraine * University ...</td>\n",
       "      <td>117032</td>\n",
       "      <td>14</td>\n",
       "      <td>(0, 100]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70479</th>\n",
       "      <td>62</td>\n",
       "      <td>= 62 =\\n\\nCategory:62</td>\n",
       "      <td>303542</td>\n",
       "      <td>8</td>\n",
       "      <td>(0, 100]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85449</th>\n",
       "      <td>Across</td>\n",
       "      <td>= Across =\\n\\n</td>\n",
       "      <td>378807</td>\n",
       "      <td>4</td>\n",
       "      <td>(0, 100]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220790</th>\n",
       "      <td>Den</td>\n",
       "      <td>= Den =\\n\\n</td>\n",
       "      <td>983477</td>\n",
       "      <td>4</td>\n",
       "      <td>(0, 100]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220927</th>\n",
       "      <td>Bludgeon</td>\n",
       "      <td>= Bludgeon =\\n\\n</td>\n",
       "      <td>983922</td>\n",
       "      <td>6</td>\n",
       "      <td>(0, 100]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244390</th>\n",
       "      <td>Cringe</td>\n",
       "      <td>= Cringe =\\n\\n</td>\n",
       "      <td>1085406</td>\n",
       "      <td>5</td>\n",
       "      <td>(0, 100]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250774</th>\n",
       "      <td>Vindicate</td>\n",
       "      <td>= Vindicate =\\n\\n</td>\n",
       "      <td>1120393</td>\n",
       "      <td>6</td>\n",
       "      <td>(0, 100]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251334</th>\n",
       "      <td>Loophole</td>\n",
       "      <td>= Loophole =\\n\\n</td>\n",
       "      <td>1124072</td>\n",
       "      <td>6</td>\n",
       "      <td>(0, 100]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252376</th>\n",
       "      <td>Format</td>\n",
       "      <td>= Format =\\n\\n</td>\n",
       "      <td>1130641</td>\n",
       "      <td>4</td>\n",
       "      <td>(0, 100]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252377</th>\n",
       "      <td>Layout</td>\n",
       "      <td>= Layout =\\n\\n</td>\n",
       "      <td>1130642</td>\n",
       "      <td>4</td>\n",
       "      <td>(0, 100]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252378</th>\n",
       "      <td>Discharge</td>\n",
       "      <td>= Discharge =\\n\\n</td>\n",
       "      <td>1130643</td>\n",
       "      <td>5</td>\n",
       "      <td>(0, 100]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252379</th>\n",
       "      <td>Footnote</td>\n",
       "      <td>= Footnote =\\n\\n</td>\n",
       "      <td>1130644</td>\n",
       "      <td>4</td>\n",
       "      <td>(0, 100]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252380</th>\n",
       "      <td>Absence</td>\n",
       "      <td>= Absence =\\n\\n</td>\n",
       "      <td>1130645</td>\n",
       "      <td>5</td>\n",
       "      <td>(0, 100]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252381</th>\n",
       "      <td>Accessory</td>\n",
       "      <td>= Accessory =\\n\\n</td>\n",
       "      <td>1130647</td>\n",
       "      <td>5</td>\n",
       "      <td>(0, 100]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252382</th>\n",
       "      <td>Arbitrary</td>\n",
       "      <td>= Arbitrary =\\n\\n</td>\n",
       "      <td>1130648</td>\n",
       "      <td>5</td>\n",
       "      <td>(0, 100]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258230</th>\n",
       "      <td>The True Story of the 3 Little Pigs</td>\n",
       "      <td>= The True Story of the 3 Little Pigs =\\n\\n</td>\n",
       "      <td>1155422</td>\n",
       "      <td>13</td>\n",
       "      <td>(0, 100]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258516</th>\n",
       "      <td>The Grand Old Duke of Noble York</td>\n",
       "      <td>= The Grand Old Duke of Noble York =\\n\\n</td>\n",
       "      <td>1156573</td>\n",
       "      <td>10</td>\n",
       "      <td>(0, 100]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258517</th>\n",
       "      <td>Naughty Sock (1997)</td>\n",
       "      <td>= Naughty Sock (1997) =\\n\\n</td>\n",
       "      <td>1156574</td>\n",
       "      <td>11</td>\n",
       "      <td>(0, 100]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258519</th>\n",
       "      <td>Playing in the Rain</td>\n",
       "      <td>= Playing in the Rain =\\n\\n</td>\n",
       "      <td>1156577</td>\n",
       "      <td>7</td>\n",
       "      <td>(0, 100]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-31T18:04:33.212809Z",
     "start_time": "2024-12-31T18:04:33.205104Z"
    }
   },
   "cell_type": "code",
   "source": "data[data[\"token_count\"] >= 7000].shape",
   "id": "ad57f83bfca5b6c2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(439, 5)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Group articles according to token count",
   "id": "59d020f160d4519d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-31T17:45:47.370680Z",
     "start_time": "2024-12-31T17:45:47.343677Z"
    }
   },
   "cell_type": "code",
   "source": [
    "token_group_size = 100\n",
    "\n",
    "# Step 1: Bin the token_count column into groups of 100\n",
    "data['token_bin'] = pd.cut(data['token_count'], bins=range(0, data['token_count'].max() + token_group_size, token_group_size))\n",
    "\n",
    "# Step 2: Count the number of rows in each bin\n",
    "bin_counts = data['token_bin'].value_counts().sort_values(ascending=False)\n",
    "\n",
    "# Step 3: Get the top 10 groups with the highest counts\n",
    "bin_counts.head(10)"
   ],
   "id": "7991d28a37c0cc89",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "token_bin\n",
       "(0, 100]       84131\n",
       "(100, 200]     72788\n",
       "(200, 300]     33628\n",
       "(300, 400]     17592\n",
       "(400, 500]     11435\n",
       "(500, 600]      7770\n",
       "(600, 700]      5434\n",
       "(700, 800]      4154\n",
       "(800, 900]      3263\n",
       "(900, 1000]     2613\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
